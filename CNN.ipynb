{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = os.getcwd()\n",
    "\n",
    "def getDatafile(file_dir):\n",
    "\n",
    "    test_list = []\n",
    "    test_label = [] \n",
    "    valide_list = []\n",
    "    valide_label = []\n",
    "    train_list = []\n",
    "    train_label = []\n",
    "    #定义存放各类别数据和对应标签的列表，列表名对应你所需要分类的列别名\n",
    "\n",
    "    file_list = []   #liste des files de wav\n",
    "    dic_list = [] # dictionnaire de base des données\n",
    "    path_list=os.listdir(file_dir)\n",
    "\n",
    "    for wav_dir in path_list:\n",
    "        name = wav_dir.split(sep='.')\n",
    "        if(len(name) == 1) :\n",
    "            for wav in os.listdir(file_dir+'/'+wav_dir): \n",
    "                name_wav = wav.split(sep='.')\n",
    "                if(len(name_wav) == 2 and name_wav[1] == 'wav' ):\n",
    "                    file_list.append(wav_dir+'/'+wav)\n",
    "                    if not(wav_dir in dic_list):\n",
    "                        dic_list.append(wav_dir)\n",
    "\n",
    "    print(len(file_list))\n",
    "    print(dic_list)\n",
    "\n",
    "    index = {}\n",
    "    for i in range(len(dic_list)):\n",
    "        index[dic_list[i]] = i\n",
    "    #Creates the reverse table that maps labels names to their index\n",
    "\n",
    "    print(index)\n",
    "    \n",
    "    \n",
    "    #Creates the test_list\n",
    "    for line in open('testing_list.txt','r'):\n",
    "        test_list.append(line.strip('\\n'))\n",
    "\n",
    "    perm = np.random.permutation(len(test_list))\n",
    "    test = list()\n",
    "    for i in range(len(perm)):\n",
    "        test.append(test_list[perm[i]])\n",
    "        label = test_list[perm[i]].strip('\\n').split(sep='/')[0]\n",
    "        test_label.append(index[label])\n",
    "\n",
    "\n",
    "    #Creates the valide_list\n",
    "    for line in open('validation_list.txt','r'):\n",
    "        valide_list.append(line.strip('\\n'))\n",
    "    perm = np.random.permutation(len(valide_list))\n",
    "    valide = list()\n",
    "    for i in range(len(perm)):\n",
    "        valide.append(valide_list[perm[i]])\n",
    "        label = valide_list[perm[i]].strip('\\n').split(sep='/')[0]\n",
    "        valide_label.append(index[label])\n",
    "\n",
    "\n",
    "    #Creates the train_list\n",
    "    for line in file_list:\n",
    "        if not (line in test_list ):\n",
    "            if not (line in valide_list):\n",
    "                train_list.append(line)\n",
    "    perm = np.random.permutation(len(train_list))\n",
    "    train = list()\n",
    "    for i in range(len(perm)):\n",
    "        train.append(train_list[perm[i]])\n",
    "        label = train_list[perm[i]].split(sep='/')[0]\n",
    "        train_label.append(index[label])\n",
    "        \n",
    "        \n",
    "    return index, train, train_label, valide, valide_label, test, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105829\n",
      "['right', 'eight', 'cat', 'tree', 'backward', 'learn', 'bed', 'happy', 'go', 'dog', 'no', 'wow', 'follow', 'nine', 'left', 'stop', 'three', 'sheila', 'one', 'bird', 'zero', 'seven', 'up', 'visual', 'marvin', 'two', 'house', 'down', 'six', 'yes', 'on', 'five', 'forward', 'off', 'four']\n",
      "{'right': 0, 'eight': 1, 'cat': 2, 'tree': 3, 'backward': 4, 'learn': 5, 'bed': 6, 'happy': 7, 'go': 8, 'dog': 9, 'no': 10, 'wow': 11, 'follow': 12, 'nine': 13, 'left': 14, 'stop': 15, 'three': 16, 'sheila': 17, 'one': 18, 'bird': 19, 'zero': 20, 'seven': 21, 'up': 22, 'visual': 23, 'marvin': 24, 'two': 25, 'house': 26, 'down': 27, 'six': 28, 'yes': 29, 'on': 30, 'five': 31, 'forward': 32, 'off': 33, 'four': 34}\n"
     ]
    }
   ],
   "source": [
    "index, train, train_label, valide, valide_label, test, test_label = getDatafile(file_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 forward/6347b393_nohash_0.wav\n",
      "32\n",
      "1000 zero/5e1b34a6_nohash_1.wav\n",
      "20\n",
      "2000 one/54b6d355_nohash_0.wav\n",
      "18\n",
      "3000 three/f0ebef1b_nohash_1.wav\n",
      "16\n",
      "4000 learn/1b18600d_nohash_0.wav\n",
      "5\n",
      "5000 one/8a28231e_nohash_0.wav\n",
      "18\n",
      "6000 one/98f4f088_nohash_0.wav\n",
      "18\n",
      "7000 on/c50f55b8_nohash_17.wav\n",
      "30\n",
      "8000 go/64df20d8_nohash_1.wav\n",
      "8\n",
      "9000 right/61e2f74f_nohash_2.wav\n",
      "0\n",
      "10000 yes/f33660af_nohash_0.wav\n",
      "29\n",
      "11000 one/00f0204f_nohash_0.wav\n",
      "18\n",
      "12000 sheila/e04d7130_nohash_0.wav\n",
      "17\n",
      "13000 one/d394ef8e_nohash_2.wav\n",
      "18\n",
      "14000 three/5fc3ed24_nohash_1.wav\n",
      "16\n",
      "15000 five/a583c5b0_nohash_0.wav\n",
      "31\n",
      "16000 happy/f6617a86_nohash_0.wav\n",
      "7\n",
      "17000 wow/4c13fe25_nohash_0.wav\n",
      "11\n",
      "18000 sheila/d85270c1_nohash_0.wav\n",
      "17\n",
      "19000 off/85851131_nohash_2.wav\n",
      "33\n",
      "20000 dog/de89e2ca_nohash_0.wav\n",
      "9\n",
      "21000 house/b76f6088_nohash_0.wav\n",
      "26\n",
      "22000 eight/5f8e50a0_nohash_0.wav\n",
      "1\n",
      "23000 bed/ae04cdbe_nohash_0.wav\n",
      "6\n",
      "24000 up/47565088_nohash_0.wav\n",
      "22\n",
      "25000 one/f0522ff4_nohash_2.wav\n",
      "18\n",
      "26000 off/ef3367d9_nohash_2.wav\n",
      "33\n",
      "27000 seven/f8ba7c0e_nohash_2.wav\n",
      "21\n",
      "28000 on/30a09789_nohash_0.wav\n",
      "30\n",
      "29000 wow/c2dccf38_nohash_0.wav\n",
      "11\n",
      "30000 on/472b8045_nohash_1.wav\n",
      "30\n",
      "31000 one/5a3fc246_nohash_0.wav\n",
      "18\n",
      "32000 bird/00f0204f_nohash_0.wav\n",
      "19\n",
      "33000 two/0ba018fc_nohash_0.wav\n",
      "25\n",
      "34000 marvin/72242187_nohash_0.wav\n",
      "24\n",
      "35000 no/7213ed54_nohash_3.wav\n",
      "10\n",
      "36000 four/62f05757_nohash_0.wav\n",
      "34\n",
      "37000 one/3bfd30e6_nohash_3.wav\n",
      "18\n",
      "38000 right/78030270_nohash_0.wav\n",
      "0\n",
      "39000 go/fa57ab3b_nohash_2.wav\n",
      "8\n",
      "40000 up/2dc4f05d_nohash_0.wav\n",
      "22\n",
      "41000 eight/9b8a7439_nohash_1.wav\n",
      "1\n",
      "42000 happy/9c24bc76_nohash_0.wav\n",
      "7\n",
      "43000 two/13dce503_nohash_1.wav\n",
      "25\n",
      "44000 six/bbd0bbd0_nohash_1.wav\n",
      "28\n",
      "45000 zero/cd7f8c1b_nohash_2.wav\n",
      "20\n",
      "46000 two/a1c63f25_nohash_0.wav\n",
      "25\n",
      "47000 one/da584bc0_nohash_2.wav\n",
      "18\n",
      "48000 six/e6327279_nohash_0.wav\n",
      "28\n",
      "49000 yes/57376a4c_nohash_0.wav\n",
      "29\n",
      "50000 four/3e31dffe_nohash_3.wav\n",
      "34\n",
      "51000 dog/14775481_nohash_0.wav\n",
      "9\n",
      "52000 seven/67bdbf56_nohash_0.wav\n",
      "21\n",
      "53000 up/27c24504_nohash_0.wav\n",
      "22\n",
      "54000 on/26e573a9_nohash_0.wav\n",
      "30\n",
      "55000 visual/7213ed54_nohash_3.wav\n",
      "23\n",
      "56000 cat/d8521ea0_nohash_0.wav\n",
      "2\n",
      "57000 go/735845ab_nohash_2.wav\n",
      "8\n",
      "58000 one/15574821_nohash_0.wav\n",
      "18\n",
      "59000 three/6565a81d_nohash_4.wav\n",
      "16\n",
      "60000 yes/837f7378_nohash_2.wav\n",
      "29\n",
      "61000 follow/a1e71565_nohash_2.wav\n",
      "12\n",
      "62000 down/e48a80ed_nohash_0.wav\n",
      "27\n",
      "63000 no/8dc26a15_nohash_1.wav\n",
      "10\n",
      "64000 forward/6fb3d5a7_nohash_2.wav\n",
      "32\n",
      "65000 eight/efbc3952_nohash_1.wav\n",
      "1\n",
      "66000 one/ad89eb1e_nohash_0.wav\n",
      "18\n",
      "67000 bed/b71ebf79_nohash_0.wav\n",
      "6\n",
      "68000 five/fd5ccd39_nohash_3.wav\n",
      "31\n",
      "69000 off/c692524d_nohash_0.wav\n",
      "33\n",
      "70000 go/f575faf3_nohash_3.wav\n",
      "8\n",
      "71000 zero/3bb68054_nohash_1.wav\n",
      "20\n",
      "72000 no/3d9bbe2d_nohash_0.wav\n",
      "10\n",
      "73000 no/0362539c_nohash_1.wav\n",
      "10\n",
      "74000 seven/e3e49931_nohash_0.wav\n",
      "21\n",
      "75000 happy/23abe1c9_nohash_0.wav\n",
      "7\n",
      "76000 sheila/2c7c33e8_nohash_0.wav\n",
      "17\n",
      "77000 left/7096522d_nohash_0.wav\n",
      "14\n",
      "78000 yes/d8a5ace5_nohash_1.wav\n",
      "29\n",
      "79000 bird/eb3f7d82_nohash_0.wav\n",
      "19\n",
      "80000 learn/eaa83485_nohash_1.wav\n",
      "5\n",
      "81000 no/3bc21161_nohash_2.wav\n",
      "10\n",
      "82000 yes/48bdc11c_nohash_0.wav\n",
      "29\n",
      "83000 stop/017c4098_nohash_4.wav\n",
      "15\n",
      "84000 learn/ace82a68_nohash_0.wav\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "\n",
    "nn_train = len(train)\n",
    "nx = 128\n",
    "ny = 32\n",
    "dataset  = np.zeros((nn_train,1,nx,ny))\n",
    "\n",
    "i = 0 \n",
    "for file in train :\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    melspec = librosa.feature.melspectrogram(y, sr, n_fft=1024, hop_length=512, n_mels=128)\n",
    "    logmelspec = librosa.power_to_db(melspec)\n",
    "    if logmelspec.size < 4096:\n",
    "        t=4096-logmelspec.size\n",
    "        a=np.mean(logmelspec)\n",
    "        z=np.zeros(t)\n",
    "        z.fill(a)\n",
    "#         print(tmp.shape)\n",
    "        logmelspec=(np.append(logmelspec,z))\n",
    "    elif logmelspec.size > 4096:\n",
    "        logmelspec=logmelspec[:4096]\n",
    "        \n",
    "    #print(len(logmelspec))\n",
    "        \n",
    "    if(len(logmelspec) != 128):    \n",
    "        logmelspec = np.reshape(logmelspec, (128, 32)) \n",
    "    \n",
    "    logmelspec = (logmelspec - np.min(logmelspec) )/(np.max(logmelspec)  - np.min(logmelspec))\n",
    "    \n",
    "    logmelspec = logmelspec[newaxis, :, :]\n",
    "    #dataset.append(logmelspec)\n",
    "    dataset[i] = logmelspec\n",
    "    if( i%1000 == 0):\n",
    "            print(i,file)\n",
    "            print(train_label[i])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 one/bb05582b_nohash_4.wav\n",
      "18\n",
      "1000 right/50033893_nohash_1.wav\n",
      "0\n",
      "2000 left/b49caed3_nohash_2.wav\n",
      "14\n",
      "3000 six/5ff3f9a1_nohash_1.wav\n",
      "28\n",
      "4000 stop/893705bb_nohash_6.wav\n",
      "15\n",
      "5000 two/bb05582b_nohash_0.wav\n",
      "25\n",
      "6000 zero/e1469561_nohash_2.wav\n",
      "20\n",
      "7000 nine/9a7c1f83_nohash_4.wav\n",
      "13\n",
      "8000 two/af7a8296_nohash_2.wav\n",
      "25\n",
      "9000 left/692a88e6_nohash_2.wav\n",
      "14\n",
      "10000 backward/5170b77f_nohash_4.wav\n",
      "4\n",
      "11000 three/6736bc64_nohash_0.wav\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "testset = []\n",
    "\n",
    "nn_test = len(test)\n",
    "nx = 128\n",
    "ny = 32\n",
    "testset  = np.zeros((nn_test,1,nx,ny))\n",
    "\n",
    "i = 0 \n",
    "for file in test :\n",
    "    y, sr = librosa.load(file, sr=None)\n",
    "    melspec = librosa.feature.melspectrogram(y, sr, n_fft=1024, hop_length=512, n_mels=128)\n",
    "    logmelspec = librosa.power_to_db(melspec)\n",
    "    if logmelspec.size < 4096:\n",
    "        t=4096-logmelspec.size\n",
    "        a=np.mean(logmelspec)\n",
    "        z=np.zeros(t)\n",
    "        z.fill(a)\n",
    "#         print(tmp.shape)\n",
    "        logmelspec=(np.append(logmelspec,z))\n",
    "    elif logmelspec.size > 4096:\n",
    "        logmelspec=logmelspec[:4096]\n",
    "        \n",
    "    if(len(logmelspec) != 128):    \n",
    "          logmelspec = np.reshape(logmelspec, (128, 32)) \n",
    "    \n",
    "    logmelspec = (logmelspec - np.min(logmelspec) )/(np.max(logmelspec)  - np.min(logmelspec))\n",
    "    #print(logmelspec)\n",
    "    logmelspec = logmelspec[newaxis, :, :]\n",
    "    #dataset.append(logmelspec)\n",
    "    testset[i] = logmelspec\n",
    "    if( i%1000 == 0):\n",
    "            print(i,file)\n",
    "            print(test_label[i])\n",
    "    i+=1\n",
    "    \n",
    "    #if(i>11000): print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable # torch 中 Variable 模块\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "#train_tensor = transform1(dataset)\n",
    "train_tensor = torch.tensor(dataset).float()\n",
    "\n",
    "target_tensor = torch.tensor(train_label)\n",
    "\n",
    "print(type(train_tensor))\n",
    "\n",
    "#print(target_tensor[0])\n",
    "torch_dataset = torch.utils.data.TensorDataset(train_tensor, target_tensor)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(torch_dataset, batch_size=2,\n",
    "                                          shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5007, 0.5536, 0.5257,  ..., 0.4672, 0.5024, 0.5025],\n",
      "          [0.5354, 0.5740, 0.5765,  ..., 0.4846, 0.5019, 0.3655],\n",
      "          [0.3113, 0.4641, 0.5609,  ..., 0.5033, 0.5235, 0.4922],\n",
      "          ...,\n",
      "          [0.3485, 0.3485, 0.3485,  ..., 0.3485, 0.3485, 0.3485],\n",
      "          [0.3485, 0.3485, 0.3485,  ..., 0.3485, 0.3485, 0.3485],\n",
      "          [0.3485, 0.3485, 0.3485,  ..., 0.3485, 0.3485, 0.3485]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.4903,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.4807,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.4016,  ..., 0.0000, 0.0000, 0.0000]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-26:\n",
      "Process Process-25:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images)\n",
    "\n",
    "images1, labels1 = dataiter.next()\n",
    "\n",
    "#print(np.max(images1[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x1ce4ccea58>\n"
     ]
    }
   ],
   "source": [
    "test_tensor = torch.tensor(testset).float()\n",
    "target_test = torch.tensor(test_label)\n",
    "\n",
    "#print(test_tensor[0][0][0])\n",
    "\n",
    "#print(target_tensor[0])\n",
    "torch_testset = torch.utils.data.TensorDataset(test_tensor, target_test)\n",
    "\n",
    "\n",
    "#print(torch_testset[0])\n",
    "testloader = torch.utils.data.DataLoader(torch_testset, batch_size=2,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "print(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,16,7)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.fc1 = nn.Linear(64 * 13 * 1, 35)\n",
    "        #self.fc2 = nn.Linear(256, 256)\n",
    "        #self.fc3 = nn.Linear(256, 35)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        #print(x[0])\n",
    "        x = x.view(-1, 64 * 13 * 1)\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.826\n",
      "[1,  4000] loss: 0.853\n",
      "[1,  6000] loss: 0.823\n",
      "[1,  8000] loss: 0.869\n",
      "[1, 10000] loss: 0.833\n",
      "[1, 12000] loss: 0.834\n",
      "[1, 14000] loss: 0.860\n",
      "[1, 16000] loss: 0.885\n",
      "[1, 18000] loss: 0.884\n",
      "[1, 20000] loss: 0.844\n",
      "[1, 22000] loss: 0.857\n",
      "[1, 24000] loss: 0.835\n",
      "[1, 26000] loss: 0.844\n",
      "[1, 28000] loss: 0.841\n",
      "[1, 30000] loss: 0.840\n",
      "[1, 32000] loss: 0.859\n",
      "[1, 34000] loss: 0.859\n",
      "[1, 36000] loss: 0.847\n",
      "[1, 38000] loss: 0.827\n",
      "[1, 40000] loss: 0.857\n",
      "[1, 42000] loss: 0.814\n",
      "[2,  2000] loss: 0.862\n",
      "[2,  4000] loss: 0.821\n",
      "[2,  6000] loss: 0.837\n",
      "[2,  8000] loss: 0.818\n",
      "[2, 10000] loss: 0.842\n",
      "[2, 12000] loss: 0.855\n",
      "[2, 14000] loss: 0.838\n",
      "[2, 16000] loss: 0.842\n",
      "[2, 18000] loss: 0.816\n",
      "[2, 20000] loss: 0.853\n",
      "[2, 22000] loss: 0.851\n",
      "[2, 24000] loss: 0.813\n",
      "[2, 26000] loss: 0.827\n",
      "[2, 28000] loss: 0.849\n",
      "[2, 30000] loss: 0.804\n",
      "[2, 32000] loss: 0.853\n",
      "[2, 34000] loss: 0.834\n",
      "[2, 36000] loss: 0.811\n",
      "[2, 38000] loss: 0.820\n",
      "[2, 40000] loss: 0.813\n",
      "[2, 42000] loss: 0.826\n",
      "[3,  2000] loss: 0.818\n",
      "[3,  4000] loss: 0.828\n",
      "[3,  6000] loss: 0.839\n",
      "[3,  8000] loss: 0.838\n",
      "[3, 10000] loss: 0.815\n",
      "[3, 12000] loss: 0.814\n",
      "[3, 14000] loss: 0.803\n",
      "[3, 16000] loss: 0.835\n",
      "[3, 18000] loss: 0.835\n",
      "[3, 20000] loss: 0.797\n",
      "[3, 22000] loss: 0.839\n",
      "[3, 24000] loss: 0.800\n",
      "[3, 26000] loss: 0.845\n",
      "[3, 28000] loss: 0.846\n",
      "[3, 30000] loss: 0.794\n",
      "[3, 32000] loss: 0.842\n",
      "[3, 34000] loss: 0.818\n",
      "[3, 36000] loss: 0.808\n",
      "[3, 38000] loss: 0.805\n",
      "[3, 40000] loss: 0.814\n",
      "[3, 42000] loss: 0.806\n",
      "[4,  2000] loss: 0.846\n",
      "[4,  4000] loss: 0.787\n",
      "[4,  6000] loss: 0.829\n",
      "[4,  8000] loss: 0.799\n",
      "[4, 10000] loss: 0.830\n",
      "[4, 12000] loss: 0.790\n",
      "[4, 14000] loss: 0.795\n",
      "[4, 16000] loss: 0.783\n",
      "[4, 18000] loss: 0.785\n",
      "[4, 20000] loss: 0.813\n",
      "[4, 22000] loss: 0.823\n",
      "[4, 24000] loss: 0.806\n",
      "[4, 26000] loss: 0.763\n",
      "[4, 28000] loss: 0.808\n",
      "[4, 30000] loss: 0.821\n",
      "[4, 32000] loss: 0.791\n",
      "[4, 34000] loss: 0.838\n",
      "[4, 36000] loss: 0.814\n",
      "[4, 38000] loss: 0.807\n",
      "[4, 40000] loss: 0.797\n",
      "[4, 42000] loss: 0.837\n",
      "[5,  2000] loss: 0.808\n",
      "[5,  4000] loss: 0.787\n",
      "[5,  6000] loss: 0.809\n",
      "[5,  8000] loss: 0.759\n",
      "[5, 10000] loss: 0.788\n",
      "[5, 12000] loss: 0.771\n",
      "[5, 14000] loss: 0.801\n",
      "[5, 16000] loss: 0.820\n",
      "[5, 18000] loss: 0.804\n",
      "[5, 20000] loss: 0.799\n",
      "[5, 22000] loss: 0.789\n",
      "[5, 24000] loss: 0.779\n",
      "[5, 26000] loss: 0.810\n",
      "[5, 28000] loss: 0.808\n",
      "[5, 30000] loss: 0.837\n",
      "[5, 32000] loss: 0.805\n",
      "[5, 34000] loss: 0.808\n",
      "[5, 36000] loss: 0.817\n",
      "[5, 38000] loss: 0.770\n",
      "[5, 40000] loss: 0.773\n",
      "[5, 42000] loss: 0.781\n",
      "[6,  2000] loss: 0.773\n",
      "[6,  4000] loss: 0.803\n",
      "[6,  6000] loss: 0.781\n",
      "[6,  8000] loss: 0.782\n",
      "[6, 10000] loss: 0.807\n",
      "[6, 12000] loss: 0.777\n",
      "[6, 14000] loss: 0.801\n",
      "[6, 16000] loss: 0.775\n",
      "[6, 18000] loss: 0.808\n",
      "[6, 20000] loss: 0.745\n",
      "[6, 22000] loss: 0.789\n",
      "[6, 24000] loss: 0.797\n",
      "[6, 26000] loss: 0.821\n",
      "[6, 28000] loss: 0.770\n",
      "[6, 30000] loss: 0.775\n",
      "[6, 32000] loss: 0.800\n",
      "[6, 34000] loss: 0.821\n",
      "[6, 36000] loss: 0.787\n",
      "[6, 38000] loss: 0.772\n",
      "[6, 40000] loss: 0.725\n",
      "[6, 42000] loss: 0.776\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable # torch 中 Variable 模块\n",
    "\n",
    "for epoch in range(30):  # loop over the dataset multiple times \n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs = Variable(data[0])\n",
    "        labels = Variable(data[1])\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        #print(outputs)\n",
    "        # _,predicted = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([30,  0])\n",
      "tensor([30,  0])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "\n",
    "inputs, labels = dataiter.next()\n",
    "\n",
    "print(labels)\n",
    "\n",
    "outputs = net(inputs)\n",
    "\n",
    "_,predicted = torch.max(outputs, 1)\n",
    "\n",
    "print(predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> correct 2 : \t100%\n",
      "--> correct 162 : \t80%\n",
      "--> correct 309 : \t77%\n",
      "--> correct 478 : \t79%\n",
      "--> correct 633 : \t79%\n",
      "--> correct 788 : \t79%\n",
      "--> correct 947 : \t79%\n",
      "--> correct 1101 : \t79%\n",
      "--> correct 1250 : \t78%\n",
      "--> correct 1419 : \t79%\n",
      "--> correct 1585 : \t79%\n",
      "--> correct 1752 : \t80%\n",
      "--> correct 1916 : \t80%\n",
      "--> correct 2070 : \t80%\n",
      "--> correct 2228 : \t80%\n",
      "--> correct 2382 : \t79%\n",
      "--> correct 2541 : \t79%\n",
      "--> correct 2702 : \t79%\n",
      "--> correct 2859 : \t79%\n",
      "--> correct 3017 : \t79%\n",
      "--> correct 3186 : \t80%\n",
      "--> correct 3341 : \t80%\n",
      "--> correct 3498 : \t79%\n",
      "--> correct 3659 : \t80%\n",
      "--> correct 3811 : \t79%\n",
      "--> correct 3967 : \t79%\n",
      "--> correct 4113 : \t79%\n",
      "--> correct 4264 : \t79%\n",
      "--> correct 4422 : \t79%\n",
      "--> correct 4575 : \t79%\n",
      "--> correct 4731 : \t79%\n",
      "--> correct 4885 : \t79%\n",
      "--> correct 5039 : \t79%\n",
      "--> correct 5197 : \t79%\n",
      "--> correct 5352 : \t79%\n",
      "--> correct 5519 : \t79%\n",
      "--> correct 5673 : \t79%\n",
      "--> correct 5828 : \t79%\n",
      "--> correct 5977 : \t79%\n",
      "--> correct 6133 : \t79%\n",
      "--> correct 6288 : \t79%\n",
      "--> correct 6444 : \t79%\n",
      "--> correct 6601 : \t79%\n",
      "--> correct 6756 : \t79%\n",
      "--> correct 6917 : \t79%\n",
      "--> correct 7068 : \t79%\n",
      "--> correct 7216 : \t78%\n",
      "--> correct 7371 : \t78%\n",
      "--> correct 7529 : \t78%\n",
      "--> correct 7688 : \t78%\n",
      "--> correct 7842 : \t78%\n",
      "--> correct 7993 : \t78%\n",
      "--> correct 8159 : \t78%\n",
      "--> correct 8321 : \t78%\n",
      "--> correct 8488 : \t79%\n",
      "--> correct 8645 : \t79%\n",
      "--> correct 8798 : \t79%\n",
      "--> correct 8959 : \t79%\n",
      "--> correct 9114 : \t79%\n",
      "--> correct 9275 : \t79%\n",
      "--> correct 9428 : \t79%\n",
      "--> correct 9581 : \t79%\n",
      "--> correct 9734 : \t78%\n",
      "--> correct 9887 : \t78%\n",
      "--> correct 10046 : \t78%\n",
      "--> correct 10204 : \t78%\n",
      "--> correct 10364 : \t79%\n",
      "--> correct 10520 : \t78%\n",
      "--> correct 10682 : \t79%\n",
      "--> correct 10848 : \t79%\n",
      "--> correct 11005 : \t79%\n",
      "--> correct 11166 : \t79%\n",
      "--> correct 11313 : \t79%\n",
      "--> correct 11475 : \t79%\n",
      "--> correct 11626 : \t79%\n",
      "--> correct 11781 : \t79%\n",
      "--> correct 11939 : \t79%\n",
      "--> correct 12101 : \t79%\n",
      "--> correct 12249 : \t79%\n",
      "--> correct 12406 : \t79%\n",
      "--> correct 12564 : \t79%\n",
      "--> correct 12710 : \t78%\n",
      "--> correct 12865 : \t78%\n",
      "--> correct 13007 : \t78%\n",
      "--> correct 13167 : \t78%\n",
      "--> correct 13324 : \t78%\n",
      "--> correct 13475 : \t78%\n",
      "--> correct 13623 : \t78%\n",
      "--> correct 13779 : \t78%\n",
      "--> correct 13939 : \t78%\n",
      "--> correct 14088 : \t78%\n",
      "--> correct 14250 : \t78%\n",
      "--> correct 14413 : \t78%\n",
      "--> correct 14562 : \t78%\n",
      "--> correct 14713 : \t78%\n",
      "--> correct 14870 : \t78%\n",
      "--> correct 15035 : \t78%\n",
      "--> correct 15197 : \t78%\n",
      "--> correct 15352 : \t78%\n",
      "--> correct 15501 : \t78%\n",
      "--> correct 15662 : \t78%\n",
      "--> correct 15810 : \t78%\n",
      "--> correct 15960 : \t78%\n",
      "--> correct 16107 : \t78%\n",
      "--> correct 16261 : \t78%\n",
      "--> correct 16405 : \t78%\n",
      "--> correct 16566 : \t78%\n",
      "--> correct 16724 : \t78%\n",
      "--> correct 16878 : \t78%\n",
      "--> correct 17034 : \t78%\n",
      "--> correct 17190 : \t78%\n",
      "--> correct 17349 : \t78%\n",
      "--> correct 17501 : \t78%\n",
      "--> correct 17677 : \t78%\n",
      "--> correct 17833 : \t78%\n",
      "--> correct 17984 : \t78%\n",
      "--> correct 18147 : \t78%\n",
      "--> correct 18302 : \t78%\n",
      "--> correct 18465 : \t78%\n",
      "--> correct 18608 : \t78%\n",
      "--> correct 18762 : \t78%\n",
      "--> correct 18907 : \t78%\n",
      "--> correct 19064 : \t78%\n",
      "--> correct 19216 : \t78%\n",
      "--> correct 19363 : \t78%\n",
      "--> correct 19521 : \t78%\n",
      "--> correct 19679 : \t78%\n",
      "--> correct 19834 : \t78%\n",
      "--> correct 19985 : \t78%\n",
      "--> correct 20134 : \t78%\n",
      "--> correct 20291 : \t78%\n",
      "--> correct 20437 : \t78%\n",
      "--> correct 20590 : \t78%\n",
      "--> correct 20752 : \t78%\n",
      "--> correct 20913 : \t78%\n",
      "--> correct 21070 : \t78%\n",
      "--> correct 21230 : \t78%\n",
      "--> correct 21391 : \t78%\n",
      "--> correct 21545 : \t78%\n",
      "--> correct 21699 : \t78%\n",
      "--> correct 21859 : \t78%\n",
      "--> correct 22022 : \t78%\n",
      "--> correct 22180 : \t78%\n",
      "--> correct 22342 : \t78%\n",
      "--> correct 22496 : \t78%\n",
      "--> correct 22657 : \t78%\n",
      "--> correct 22815 : \t78%\n",
      "--> correct 22970 : \t78%\n",
      "--> correct 23126 : \t78%\n",
      "--> correct 23285 : \t78%\n",
      "--> correct 23437 : \t78%\n",
      "--> correct 23595 : \t78%\n",
      "--> correct 23749 : \t78%\n",
      "--> correct 23909 : \t78%\n",
      "--> correct 24064 : \t78%\n",
      "--> correct 24215 : \t78%\n",
      "--> correct 24374 : \t78%\n",
      "--> correct 24540 : \t78%\n",
      "--> correct 24696 : \t78%\n",
      "--> correct 24849 : \t78%\n",
      "--> correct 25012 : \t78%\n",
      "--> correct 25164 : \t78%\n",
      "--> correct 25326 : \t78%\n",
      "--> correct 25471 : \t78%\n",
      "--> correct 25632 : \t78%\n",
      "--> correct 25786 : \t78%\n",
      "--> correct 25936 : \t78%\n",
      "--> correct 26087 : \t78%\n",
      "--> correct 26241 : \t78%\n",
      "--> correct 26405 : \t78%\n",
      "--> correct 26568 : \t78%\n",
      "--> correct 26729 : \t78%\n",
      "--> correct 26896 : \t78%\n",
      "--> correct 27059 : \t78%\n",
      "--> correct 27223 : \t78%\n",
      "--> correct 27378 : \t78%\n",
      "--> correct 27530 : \t78%\n",
      "--> correct 27689 : \t78%\n",
      "--> correct 27858 : \t78%\n",
      "--> correct 28022 : \t78%\n",
      "--> correct 28179 : \t78%\n",
      "--> correct 28337 : \t78%\n",
      "--> correct 28482 : \t78%\n",
      "--> correct 28633 : \t78%\n",
      "--> correct 28788 : \t78%\n",
      "--> correct 28947 : \t78%\n",
      "--> correct 29111 : \t78%\n",
      "--> correct 29262 : \t78%\n",
      "--> correct 29419 : \t78%\n",
      "--> correct 29577 : \t78%\n",
      "--> correct 29727 : \t78%\n",
      "--> correct 29895 : \t78%\n",
      "--> correct 30059 : \t78%\n",
      "--> correct 30217 : \t78%\n",
      "--> correct 30373 : \t78%\n",
      "--> correct 30530 : \t78%\n",
      "--> correct 30693 : \t78%\n",
      "--> correct 30860 : \t78%\n",
      "--> correct 31017 : \t78%\n",
      "--> correct 31175 : \t78%\n",
      "--> correct 31335 : \t78%\n",
      "--> correct 31491 : \t78%\n",
      "--> correct 31642 : \t78%\n",
      "--> correct 31807 : \t78%\n",
      "--> correct 31964 : \t78%\n",
      "--> correct 32126 : \t78%\n",
      "--> correct 32277 : \t78%\n",
      "--> correct 32430 : \t78%\n",
      "--> correct 32599 : \t78%\n",
      "--> correct 32756 : \t78%\n",
      "--> correct 32918 : \t78%\n",
      "--> correct 33071 : \t78%\n",
      "--> correct 33228 : \t78%\n",
      "--> correct 33392 : \t78%\n",
      "--> correct 33544 : \t78%\n",
      "--> correct 33699 : \t78%\n",
      "--> correct 33842 : \t78%\n",
      "--> correct 33993 : \t78%\n",
      "--> correct 34148 : \t78%\n",
      "--> correct 34305 : \t78%\n",
      "--> correct 34470 : \t78%\n",
      "--> correct 34627 : \t78%\n",
      "--> correct 34788 : \t78%\n",
      "--> correct 34934 : \t78%\n",
      "--> correct 35095 : \t78%\n",
      "--> correct 35242 : \t78%\n",
      "--> correct 35398 : \t78%\n",
      "--> correct 35561 : \t78%\n",
      "--> correct 35715 : \t78%\n",
      "--> correct 35873 : \t78%\n",
      "--> correct 36025 : \t78%\n",
      "--> correct 36180 : \t78%\n",
      "--> correct 36344 : \t78%\n",
      "--> correct 36490 : \t78%\n",
      "--> correct 36643 : \t78%\n",
      "--> correct 36802 : \t78%\n",
      "--> correct 36947 : \t78%\n",
      "--> correct 37098 : \t78%\n",
      "--> correct 37250 : \t78%\n",
      "--> correct 37406 : \t78%\n",
      "--> correct 37563 : \t78%\n",
      "--> correct 37718 : \t78%\n",
      "--> correct 37879 : \t78%\n",
      "--> correct 38036 : \t78%\n",
      "--> correct 38205 : \t78%\n",
      "--> correct 38364 : \t78%\n",
      "--> correct 38527 : \t78%\n",
      "--> correct 38677 : \t78%\n",
      "--> correct 38837 : \t78%\n",
      "--> correct 39001 : \t78%\n",
      "--> correct 39164 : \t78%\n",
      "--> correct 39331 : \t78%\n",
      "--> correct 39487 : \t78%\n",
      "--> correct 39647 : \t78%\n",
      "--> correct 39812 : \t78%\n",
      "--> correct 39972 : \t78%\n",
      "--> correct 40120 : \t78%\n",
      "--> correct 40282 : \t78%\n",
      "--> correct 40438 : \t78%\n",
      "--> correct 40596 : \t78%\n",
      "--> correct 40752 : \t78%\n",
      "--> correct 40912 : \t78%\n",
      "--> correct 41066 : \t78%\n",
      "--> correct 41232 : \t78%\n",
      "--> correct 41390 : \t78%\n",
      "--> correct 41546 : \t78%\n",
      "--> correct 41707 : \t78%\n",
      "--> correct 41863 : \t78%\n",
      "--> correct 42024 : \t78%\n",
      "--> correct 42176 : \t78%\n",
      "--> correct 42340 : \t78%\n",
      "--> correct 42499 : \t78%\n",
      "--> correct 42659 : \t78%\n",
      "--> correct 42820 : \t78%\n",
      "--> correct 42978 : \t78%\n",
      "--> correct 43124 : \t78%\n",
      "--> correct 43281 : \t78%\n",
      "--> correct 43439 : \t78%\n",
      "--> correct 43587 : \t78%\n",
      "--> correct 43746 : \t78%\n",
      "--> correct 43893 : \t78%\n",
      "--> correct 44059 : \t78%\n",
      "--> correct 44209 : \t78%\n",
      "--> correct 44363 : \t78%\n",
      "--> correct 44520 : \t78%\n",
      "--> correct 44668 : \t78%\n",
      "--> correct 44820 : \t78%\n",
      "--> correct 44980 : \t78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-189:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> correct 45133 : \t78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "Process Process-190:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-114-12b7fe07269e>\", line 3, in <module>\n",
      "    for i, data in enumerate(trainloader, 0):\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 330, in __next__\n",
      "    idx, batch = self._get_batch()\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 309, in _get_batch\n",
      "    return self.data_queue.get()\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/multiprocessing/synchronize.py\", line 99, in __exit__\n",
      "    return self._semlock.__exit__(*args)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/inspect.py\", line 1451, in getframeinfo\n",
      "    index = lineno - 1 - start\n",
      "  File \"/anaconda3/envs/python3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 20810) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "corret = 0\n",
    "summ = 0\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    inputs = Variable(data[0])\n",
    "    labels = Variable(data[1])\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    _,predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    if (predicted[0] == labels[0] ) : corret += 1\n",
    "    if(len(predicted) == 2):\n",
    "        if (predicted[1] == labels[1] ) : corret += 1\n",
    "        \n",
    "    summ += 2\n",
    "    \n",
    "    if (i%100 == 0 ) : print(f\"--> correct {corret} : \\t{round(corret/summ*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> correct 2 : \t100%\n",
      "--> correct 153 : \t76%\n",
      "--> correct 302 : \t75%\n",
      "--> correct 456 : \t76%\n",
      "--> correct 606 : \t76%\n",
      "--> correct 753 : \t75%\n",
      "--> correct 904 : \t75%\n",
      "--> correct 1058 : \t75%\n",
      "--> correct 1212 : \t76%\n",
      "--> correct 1361 : \t76%\n",
      "--> correct 1510 : \t75%\n",
      "--> correct 1667 : \t76%\n",
      "--> correct 1804 : \t75%\n",
      "--> correct 1947 : \t75%\n",
      "--> correct 2088 : \t75%\n",
      "--> correct 2234 : \t74%\n",
      "--> correct 2383 : \t74%\n",
      "--> correct 2528 : \t74%\n",
      "--> correct 2678 : \t74%\n",
      "--> correct 2826 : \t74%\n",
      "--> correct 2975 : \t74%\n",
      "--> correct 3132 : \t75%\n",
      "--> correct 3283 : \t75%\n",
      "--> correct 3433 : \t75%\n",
      "--> correct 3586 : \t75%\n",
      "--> correct 3739 : \t75%\n",
      "--> correct 3901 : \t75%\n",
      "--> correct 4055 : \t75%\n",
      "--> correct 4214 : \t75%\n",
      "--> correct 4367 : \t75%\n",
      "--> correct 4521 : \t75%\n",
      "--> correct 4662 : \t75%\n",
      "--> correct 4830 : \t75%\n",
      "--> correct 4977 : \t75%\n",
      "--> correct 5129 : \t75%\n",
      "--> correct 5277 : \t75%\n",
      "--> correct 5430 : \t75%\n",
      "--> correct 5582 : \t75%\n",
      "--> correct 5725 : \t75%\n",
      "--> correct 5871 : \t75%\n",
      "--> correct 6010 : \t75%\n",
      "--> correct 6168 : \t75%\n",
      "--> correct 6315 : \t75%\n",
      "--> correct 6484 : \t75%\n",
      "--> correct 6634 : \t75%\n",
      "--> correct 6785 : \t75%\n",
      "--> correct 6935 : \t75%\n",
      "--> correct 7080 : \t75%\n",
      "--> correct 7235 : \t75%\n",
      "--> correct 7404 : \t76%\n",
      "--> correct 7553 : \t76%\n",
      "--> correct 7707 : \t76%\n",
      "--> correct 7860 : \t76%\n",
      "--> correct 8020 : \t76%\n",
      "--> correct 8161 : \t76%\n",
      "--> correct 8315 : \t76%\n"
     ]
    }
   ],
   "source": [
    "corret = 0\n",
    "summ = 0\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs = Variable(data[0])\n",
    "    labels = Variable(data[1])\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    _,predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    if (predicted[0] == labels[0] ) : corret += 1\n",
    "    if(len(predicted) == 2):\n",
    "        if (predicted[1] == labels[1] ) : corret += 1  \n",
    "        \n",
    "    summ += 2\n",
    "    \n",
    "    if (i%100 == 0 ) : print(f\"--> correct {corret} : \\t{round(corret/summ*100)}%\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to model_30.pth. You can run `python evaluate.py --model model_30.pth` to generate the Kaggle formatted csv file\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/python3/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "model_file = 'model_30.pth'\n",
    "torch.save(Net, model_file)\n",
    "print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
